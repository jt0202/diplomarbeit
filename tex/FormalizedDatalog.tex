\chapter{Formalization of Datalog}\label{sec:formDatalog}
In the previous section, we introduced datalog. Our goal is to check whether ground atoms are the result of correct datalog derivations. A correctness proof requires us to define what correct derivations are which we solve by formalizing the syntax and semantics of datalog in Lean. As of writing, there is to the best of our knowledge no formalization of datalog in Lean yet. 

There does exist a formalization of datalog in Coq\cite{datalogCoq} which includes the syntax of datalog and the fixed point semantics of datalog with a datalog engine that is proven to be correct. Similarly, we will also formalize the syntax of datalog. After that, the paths will diverge as we are interested in the proof-theoretic semantics of datalog to check proof trees. Additionally, we will also formalize the model-theoretic semantics of datalog for completeness arguments and to have extra security that our formalization is correct by proving that both semantics are equivalent.

\section{Syntax}

We recall from the preliminaries that an atom is of the form $A(t_1, \dots ,t_n)$ for sets of relation symbols, variables and constants $R, V$ and $C$ and an arity function $ar: P \to \mathbb{N}$. If we were to directly formalize this an atom would be defined in the following way, where we use types instead of sets.

\begin{lstlisting}
    def atom (C: Type) (P: Type) (V: Type) (ar: P $\to$ $\mathbb{N}$): Type := sorry
\end{lstlisting}

Such a definition is rather verbose with already four arguments. Anything like the semantics that will use atoms will require even more arguments. To have a more compact representation we reuse the definition of a signature that shrinks the number of arguments to just one.  We use types instead of sets as this is more natural in type theory. If we were to use sets we would have to decide already which type these sets should have which seems unclear for now. This allows us to instead define later the types we want to use. Even if this is not an issue and we decide to use for relation symbols a set $R$ of type \lstinline|Set A|. Then any relation symbol $r$ also has the type $A$ but $R$ might not contain every element of the type $A$, so that we additionally require a proof that $r$ is in $R$. Such a membership is not required when using a type for the relation symbols as a term which would be the relation symbol $r$ has always exactly one type. 

The formalization showed us that the requirements of countability of the sets $R$, $C$ and $V$ were not required. Any result we wanted to prove holds already in this general case. Therefore we forego of modelling this assumption.

A \signature is then a structure that has a type for constants, variables\footnote{We use vars instead because variable(s) is a keyword in Lean} and relation symbols and an arity function.

\begin{lstlisting}
structure (.\signature.) where
  (constants: Type)
  (vars: Type)
  (relationSymbols: Type)
  (relationArity: relationSymbols → ℕ)
\end{lstlisting}

In the following, unless denoted otherwise, we will always use a fixed signature $\tau$ and assume that all types have instances for \lstinline|DecidableEq| and \lstinline|Hashable| classes to use Lean's automatic derivation for later uses in the program. 

Another requirement was that the sets of constants and variables are distinct. This proved again to be unnecessary in our formalization because we define terms as an inductive type with a constructor for the constant and the variable case. Therefore constants and variables in an atom will always be distinct.

\begin{lstlisting}
    inductive (.\term.) (τ: signature): Type
    | constant : τ.constants → term τ
    | variableDL : τ.vars → term τ
    deriving DecidableEq, Hashable
\end{lstlisting}

For an atom we have fields for the symbol, the list of terms and a proof that the length of the list of terms matches the arity of the symbol.

\begin{lstlisting}
structure (.\atom.) where
  (symbol: τ.relationSymbols)
  (atom_terms: List (term τ ))
  (term_length: atom_terms.length = τ.relationArity symbol)
deriving DecidableEq, Hashable
\end{lstlisting}

Two structures of the same type are equal iff all their fields are equal. Due to proof irrelevance, we gain the following expected criteria for the equality of atoms.

\begin{lemma}[\atomEquality]\label{lem:atomEquality}
    For all $\tau$-atoms $a_1, a_2$, we have $a_1 = a_2$ iff their \lstinline|symbol|s and \lstinline|atom_term|s are equal.
\end{lemma}

Rules and programs can be modeled straightforwardly. Here we use lists to have the body in a fixed order because this simplifies later algorithms.

\begin{lstlisting}
structure (.\datalogrule.) where
  (head: atom τ)
  (body: List (atom τ))
deriving DecidableEq

abbrev (.\program.) := Finset (rule τ)
\end{lstlisting}

Next, we want to define the ground versions of our previous definitions. Groundings are simply the functions from variables to constants.

\begin{lstlisting}
    def (.\grounding.) (τ: signature):= τ.vars → τ.constants
\end{lstlisting}

We see multiple ways to define ground atoms. Firstly, we can define them like we defined atoms but use constants instead of terms. 

\begin{lstlisting}
structure (.\groundAtom.) (τ: signature) where
  symbol: τ.relationSymbols
  atom_terms: List (τ.constants)
  term_length: atom_terms.length = τ.relationArity symbol
deriving DecidableEq, Hashable
\end{lstlisting}

Secondly, we can define ground atoms as a special type of atom by constructing a new structure consisting of an atom and a proof that for all terms in the atom exists some constant that is equal to it.

\begin{lstlisting}
structure groundAtom (τ: signature) where
    atom: atom τ
    ground: $\forall$ (t: term τ), t $\in$ atom.atom_terms $\rightarrow$ $\exists$ (c: τ.constants), t = term.constant c
\end{lstlisting}

The second variant allows us an easy conversion from ground atoms to atoms by simply returning the atom element. Also, we can convert atoms easily to ground atoms as soon as we have the proof. These conversions have to be written by hand in the first variant.

The first variant on the other hand allows us to define functions that create ground atoms more directly. We can take a grounding and just map the term list using the grounding without having to provide a proof that all terms of the atom are then equal to some constant. In the second variant, we have to first define the function on the atom level and then have to prove that this operation does not create any variables. This may sound like extra security in case we mess things up, but when defining the terms as a list of constants the type checker of the kernel does the check for us.

The number of conversions is rather limited whereas an easier way to define functions may be useful more often. Therefore we chose the first variant. 

We start by defining these conversions that we now have to do manually. We can convert a ground atom to an atom by mapping every constant to a term via \lstinline|term.constant|. The map operation does not change the length of a list of atoms so that the term length property is preserved(\listMapPreservesTermLength).

\begin{lstlisting}
    def (.\groundAtomtoAtom.) (ga: groundAtom τ): atom τ:= {
        symbol:=ga.symbol, 
        atom_terms:= List.map term.constant ga.atom_terms,term_length:= listMapPreservesTermLength ga
    }
\end{lstlisting}

For later proofs, it is useful to know that this is an embedding of the ground atoms into the atoms, i.e. that if two ground atoms are different then the result of their toAtom functions is also different.

For this, we need the following result (\listMapInjectiveEquality): If two lists $l_1, l_2$ are equal then mapping both lists by the same function $f$ results in the same list $l$. If the function is injective the back direction holds as well, i.e. if mapping $l_1$ and $l_2$ using $f$ yields the same list $l$ then also $l_1$ and $l_2$ are equal,  which we can prove by induction.

\begin{lemma}[\groundAtomToAtomEquality]
    Let $a_1, a_2$ be two ground atoms. Then $a_1$ is equal to $a_2$ iff the result of \lstinline|groundAtom.toAtom| of both is equal.
\end{lemma}
\begin{proof}
    If $a_1$ = $a_2$, then also the result of applying \lstinline|toAtom| to both of them is the same.

    For the back direction, we know that the results of applying \lstinline|toAtom| to $a_1$ and $a_2$ are equal and want to show that $a_1$ is equal to $a_2$. We use a similar lemma as \cref{lem:atomEquality} for ground atoms(\groundAtomEquality). Therefore we have to show that their symbols and terms are equal. As \lstinline|toAtom| does not change the symbol, the first part follows. For the second part, we have to show the term lists of $a_1$ and $a_2$ are equal. We know that mapping every constant in the atom terms of $a_1$ and $a_2$  via the \lstinline|term.constant| function yields the same list. Any inductive constructor such as \lstinline|term.constant| is injective \footnote{This can be shown with the \lstinline|injection| tactic} and hence we can use \listMapInjectiveEquality to see that the term lists of $a_1$ and $a_2$ are equal.
\end{proof}

We can therefore employ \lstinline|groundAtom.toAtom| safely as the type coercion from ground atom to atom.

In order to convert atoms to ground atoms, it would be enough to use a proposition that says that all elements are constants. In later uses such as the definition of safety for rules, it will be beneficial to have a function that computes all variables that occur in an atom. If this returns the empty set, this is the required proof to convert an atom into a ground atom. 

We can define the variables occurring in a term as a finite set.

\begin{lstlisting}
def (.\termVariables.): term τ → Finset τ.vars
| (term.constant _) => ∅
| (term.variableDL v) => {v}
\end{lstlisting}

The variables occurring in an atom are then the union of the term variables of its terms. This can be recursively expressed using \lstinline|List.foldl|. We start with the empty set and return the union with this set and the term variables of every term occurring in the atom by recursively taking the union of the previous result and the term variables of the element at the start of the list.

\begin{lstlisting}
def (.\Listfoldlunion.) {A B: Type} [DecidableEq B]  
(f: A → Finset B) (init: Finset B) (l: List A): Finset B :=
 List.foldl (fun x y => x ∪ f y) init l

def (.\atomVariables.) (a: atom τ) : Finset τ.vars := 
List.foldl_union termVariables ∅ a.atom_terms
\end{lstlisting}

If the term variables are empty, we know that the term must be a constant. We can convert a term to a constant with a function that takes a term and a proof that its term variables are empty. In the variable case, which is impossible to occur given the arguments as we have a proof that there are no term variables, we use \lstinline|False.elim| which uses that anything follows from a false proposition to generate an object of the right type. This can never be returned and is only there for completeness.

\begin{lstlisting}
def (.\termWithoutVariablesToConstant.) (t: term τ) (h: termVariables t = ∅): τ.constants :=
  match t with
  | term.constant c => c
  | term.variableDL v =>
      have h': False := by
        unfold termVariables at h
        simp at h
      False.elim h'
\end{lstlisting}

We use this function to convert atoms with no variables to ground atoms. If the atom variables of some atom $a$ are empty, then also the term variables of every term $t$ in $a$ are empty (\atomVariablesEmptyIffAllTermVariablesEmpty). Using this we can call \termWithoutVariablesToConstant on every term in the atom. We require a proof that an element is in the list, which is given by \lstinline|List.attach| together with the element itself.

\begin{lstlisting}
def (.\atomWithoutVariablesToGroundAtom.) (a: atom τ) (h: atomVariables a = ∅): groundAtom τ :=
{
  symbol:= a.symbol,
  atom_terms := List.map (fun ⟨x, _h⟩ => termWithoutVariablesToConstant x (Iff.mp (atomVariablesEmptyIffAllTermVariablesEmpty a) h x _h)) a.atom_terms.attach,
  term_length :=
    by
      simp
      apply a.term_length
}
\end{lstlisting}

After defining the conversions we define ground rules similar to rules.

\begin{lstlisting}
structure (.\groundRule.) (τ: signature) where
  head: groundAtom τ
  body: List (groundAtom τ)
deriving DecidableEq
\end{lstlisting}

We can apply a grounding to a term by replacing a variable by its grounding result and keeping the constant.
\begin{lstlisting}
def (.\applyGroundingTerm.) (g: grounding τ) (t: term τ): term τ :=
  match t with
  | term.constant c => term.constant c
  | term.variableDL v => term.constant (g v)
\end{lstlisting}

Using this function we apply groundings also to atoms and rules. 

\begin{lstlisting}
    def (.\atomGrounding.) (g: grounding τ) (a: atom τ): groundAtom τ := {
    symbol := a.symbol, 
    atom_terms := List.map (applyGroundingTerm'  g) a.atom_terms, 
    term_length := applyGroundingTerm'PreservesLength  g a
    }

    def (.\ruleGrounding.) (r: rule τ) (g:grounding τ): groundRule τ := {
        head:=atomGrounding g r.head, 
        body:= List.map (atomGrounding g) r.body 
    }

\end{lstlisting}

The ground program of a program $P$ is the set of all ground rules that are the result of the application of a grounding to a rule from $P$.

\begin{lstlisting}
    def (.\groundProgram.) (P: program τ) := 
    {r: groundRule τ | ∃ (r': rule τ) (g: grounding τ), r' ∈ P ∧ r = ruleGrounding r' g}
\end{lstlisting}

\section{Semantics}

After finishing the definition of the syntax, we start formalizing the semantics. We mentioned in the preliminaries that the semantics can be defined with or without a database. We decided to formalize the semantics with the database as this is more general. It is simpler to pass an empty database into the checker than to write every fact from the database into the rule file.

In this section, we do not want to deviate too much from the path by implementing databases in a complicated way. For now, a database is simply something that has a contains function that returns true if an element is in the database. This class can be implemented in multiple ways in the algorithm later.

\begin{lstlisting}
class (.\database.) (τ: signature) where
  (contains: groundAtom τ → Bool)
\end{lstlisting}

We call a set of ground atoms an interpretation as in the preliminaries.
\begin{lstlisting}
    abbrev (.\interpretation.) (τ: signature) := Set (groundAtom τ)
\end{lstlisting}

We start by defining the proof-theoretic semantics as proof trees are our certificates in the checker so this is the most important semantic for us.

We require the notion of a tree to formalize the proof-theoretic semantics. In mathlib exists a definition of a tree\footnote{see at \protect\url{https://leanprover-community.github.io/mathlib4_docs/Mathlib/Data/Tree.html}}, but this is despite its name only a binary tree. With Mathlib's trees, we could only represent rules in the proof tree whose body has at most length two. While any datalog program can be transformed into an equivalent program that only contains rules whose body has a length of at most two, this is not desirable as rules in practice are often longer. We could require the user to just transform the rules into this form, but this seems to hinder the acceptance of this tool and may mask errors that only occur in optimizations for longer rules.

Therefore we start by defining a tree as an element $t$ with as a vertex $a$ and a list of subtrees $l$. We call $a$ the root of $t$ and the root of the trees in $l$ the children of $t$. A leaf is an element whose subtree list is empty.

\begin{lstlisting}
inductive (.\tree.) (A: Type)
| node: A → List (tree A) → tree A

def (.\treeRoot.): tree A → A
| tree.node a _ => a

def (.\children.): tree A → List A
| tree.node _ l => List.map root l
\end{lstlisting}

An important measure for trees is the height defined as the longest path from the root to a leaf.  An alternative recursive definition is that it is the maximum of the height of all subtrees plus one, which we can implement with the listMax function.

\begin{lstlisting}
def (.\listMax.) {A: Type} (f: A → ℕ): List A → ℕ
| [] => 0
| (hd::tl) => if f hd > listMax f tl then f hd else listMax f tl

def (.\height.) (t:tree A): ℕ :=
  match t with
  | tree.node a l => 1 + listMax (fun ⟨x, _h⟩ => height x) l.attach
termination_by sizeOf t
decreasing_by
    simp_wf
    apply Nat.lt_trans (m:= sizeOf l)
    apply List.sizeOf_lt_of_mem _h
    simp
\end{lstlisting}

Our implementation looks a bit different compared to the text. This is because we are required to prove the termination of this function. We call the height function recursively, but with a list function so that we no longer follow the inductive schema directly. The well-founded relation will be the less-than relation between the \lstinline|sizeOf| results of the trees. Therefore we have to prove that \lstinline|sizeOf x < 1 + sizeOf a + sizeOf l| holds to show the termination. The term $x$ is one of the subtrees we call height on and by transitivity, it suffices to prove that \lstinline|sizeOf x < sizeOf l| holds. The size of any member of a list must be smaller than the size of the list itself by the implementation of the \lstinline|sizeOf| function. The \lstinline|List.attach| function that takes a list $l$ and maps any element $a$ from $l$ to an element of \lstinline|{ a // a  $\in$ l}|, so a pair of the original element and a proof that it is a member of $l$. This allows us to complete the proof.

We call a tree $t_2$ a \member of a tree $t_1$ if it occurs in the subtrees of $t_1$ and can prove that any member has a smaller height than the original tree (\heightOfMemberIsSmaller) because the result of $f$ for some member $a$ of $l$ is less-equal to the value of \lstinline|listMax f l|(\listMaxlefmember).

With this, we finish the general results about trees and can return to formalizing the proof-theoretic semantics. A proof tree is a tree whose vertices are ground atoms.

\begin{lstlisting}
    abbrev (.\proofTree.) (τ: signature):= tree (groundAtom τ)
\end{lstlisting}

Some proof trees will not represent valid derivations by our definition. The next step is to define a predicate that shows the validity of a tree similar to our definition in the preliminaries.

Again, we want to design our checker with the best compatibility in mind. In some papers (e.g. \cite{ComplexityProvDatalog}) the leaves of a valid proof tree have to be database elements. We leave this open to allow also facts from the program to serve as leaves for those programs that do not come with a database.

We express the validness of a proof tree with the root $a$ and the list of subtrees $l$ with respect to a program $P$ and a database $d$ by a disjunction with two disjuncts. We call the first the \textit{rule case}. There we require a rule $r$ and a grounding $g$, such that $r$ is in $P$, the rule grounding of $r$ with $g$ yields the ground rule we gain from the root and its children. Additionally, all subtrees must be valid, which we again express via \lstinline|List.attach| for the termination proof. 
The second case is the \textit{database case}. There $a$ must be a leaf and contained in the database.
This allows facts from the program as the leaves of a tree as they fulfill the rule case.

\begin{lstlisting}
def (.\isValid.) (P: program τ) (d: database τ) (t: proofTree τ): Prop :=
  match t with
  | tree.node a l => ( ∃(r: rule τ) (g:grounding τ), r ∈ P ∧ ruleGrounding r g = {head:= a, body:= (List.map root l)} ∧ l.attach.Forall (fun ⟨x, _h⟩ => isValid P d x)) 
  ∨ (l = [] ∧ d.contains a)
termination_by sizeOf t
decreasing_by
  simp_wf
  decreasing_trivial
\end{lstlisting}

We see from this definition that any element that is contained in the database has a simple proof tree. The tree is just the element as the root without any subtrees (\databaseElementsHaveValidProofTree). 

We do not consider input or export relations so that the database elements are always part of the semantics. This also simplifies the definition for \lstinline|isValid| in contrast if we only want elements that are the result of some rule to be in our semantics.

The proof-theoretic semantics with respect to a program $P$ and database $d$ is the set of ground atoms that are the root of a valid proof tree with respect to $P$ and $d$. We avoided earlier defining the types of a signature as a finite type so that we cannot expect a finite set here. We will manage to prove the same results and do not have to prove that there are only finitely many ground atoms.

\begin{lstlisting}
    def (.\proofTheoreticSemantics.) (P: program τ) (d: database τ): interpretation τ:= 
    {a: groundAtom τ | ∃ (t: proofTree τ),root t = a ∧ isValid P d t}
\end{lstlisting}

The proof-theoretic semantics provides us with proof trees a good explanation why an element is part of the solution. We only have to verify that the proof tree is correct. This however tells us only that we have found a subset of the solution. It tells us not whether there are more derivations possible. Passing an empty list of proof trees would always be accepted but this is in general not the complete solution. The other semantics are better equipped to deal with this problem. They describe the solution as the least element of some set. If we verify that the result is in this set (i.e. the set of models or the set of fixed points), then our result is a superset of the solution. If both criteria hold, then we have exactly the solution.

Formalizing another semantics also strengthens our formalization because we might spot some wrong assumptions we made in the definitions that way. If we make an error in the definition of one semantic we may spot it when trying to prove that both semantics are equal.

Both the model-theoretic and the fixed point semantics are defined to be the least object of something. We decided to formalize the model-theoretic semantics because we can directly give the model. For the fixed-point semantics, we would first need to prove that the fixed point even exists and may need some theorems about fixed points, but such a formalization (in Coq) can be found in \cite{datalogCoq}.

We start by formalizing the criteria for a rule being true. An interpretation is a set whereas a body is a list. So that we can compare them, we define the groundRuleBodySet of ground rule $r$ as the conversion of the body to a finite set. This operation preserves the members so that a ground atom is in the groundRuleBodySet of $r$ iff it is in the body of $r$.


(\groundRuleBodySetiffgroundRuleBody)


\begin{lstlisting}
    def (.\groundRuleBodySet.) (r: groundRule τ): Finset (groundAtom τ) := List.toFinset r.body
\end{lstlisting}

This allows us to define the criteria for a rule being true in an interpretation $i$ in a natural way. Whenever all elements of the body are in the interpretation, then the head must be a member of the interpretation as well.

\begin{lstlisting}
    def (.\ruleTrue.) (r: groundRule τ) (i: interpretation τ): Prop := 
    (groundRuleBodySet r).toSet ⊆ i → r.head ∈ i
\end{lstlisting}

An interpretation is a model, if all rules from the ground rule are fulfilled. Additionally, it also needs to contain the elements from the database so that we will be able to prove the equivalence of the semantics later because all elements in the database are already in the proof-theoretic semantics.

\begin{lstlisting}
    def (.\model.) (P: program τ) (d: database τ) (i: interpretation τ) : Prop := 
    (∀ (r: groundRule τ), r ∈ groundProgram P → ruleTrue r i) 
    ∧ ∀ (a: groundAtom τ), d.contains a → a ∈ i
\end{lstlisting}

Now we are equipped with the necessary tools to formalize the model-theoretic semantics.  We defined the semantics in the preliminaries as the intersection of all models, i.e.

\[\bigcap_{\text{$M$ is model of $P$}} M\] 

This operation is called \lstinline|Set.iInter| in Lean. We would need to transform the set of interpretations to an indexed family to use it. This would require us to define a type that serves as the index and a function mapping every index to a model.

\begin{lstlisting}
    def iInter (s : ι → Set α) : Set α
\end{lstlisting}

We can instead define it more directly. Sets are equal whenever they have the same members by the principle of extensionality. Therefore we also try to find a formula that is true for an element whenever it is in $\bigcap_{X: \phi(X) } X $ and can use the set comprehension to obtain the model-theoretic semantics. We know that an element is in $X \cap Y$ whenever it is in both $X$ and $Y$. We can generalize this to conclude that an element is in $\bigcap_{X: \phi(X) } X $ if it is in all sets $X$ that satisfy $\phi$. Therefore the model-theoretic semantics are the atoms that are in all models.

\begin{lstlisting}
    def (.\modelTheoreticSemantics.) (P: program τ) (d: database τ): interpretation τ := 
    {a: groundAtom τ | ∀ (i: interpretation τ), model P d i → a ∈ i}
\end{lstlisting}

We now have to prove that this is actually the least model. We start by showing that it is a subset of every model. This follows from the definitions.

\begin{lemma}[\leastModel]\label{lem:leastModel}
    Let $P$ be a program and $d$ be a database. For all models $M$ of $P$ and $d$, the model-theoretic semantics of $P$ and $d$ is a subset of $M$
\end{lemma}

Proving that our definition is a model takes a bit more work.

\begin{lemma}[\modelTheoreticSemanticsIsModel]\label{lem:modelMTS}
    For all programs $P$ and data- bases $d$ the model-theoretic semantics of $P$ and $d$ is a model.
\end{lemma}
\begin{proof}
    Let $M$ be the model-theoretic semantics of $P$ and $d$. We have to show that it fulfills both model criteria.
    We start by showing that all rules are true in $M$. We assume for a contradiction that there is a rule $r$ that is not true, i.e. that the body set is a subset of $M$, but the head of $r$ is not in $M$. Then there must be a model $M'$ of $P$ and $d$ such that the head of $r$ is not in $M'$. By \cref{lem:leastModel} we know that all elements of $M$ must be in the model of $M'$. Therefore the body of $r$ is a subset of $M'$ and since $M'$ is a model the head of $r$ must be in $M'$ which violates our assumption that the head of $r$ is not in $M'$.

    Now we show that all elements in $d$ are in $M$ as well. The proof works in the same way as before but is simpler. Suppose that this does not hold. Then there is a database element $a$ which is not in $M$. By the definition of $M$ there must exist a model $M'$ such that $a$ is not in $M'$. But any model must contain all database elements which yields the contradiction and finishes the proof.
\end{proof}

The remainder of this chapter is spent proving the equivalence of both semantics, i.e. the following theorem.

\begin{lstlisting}
    theorem (.\SemanticsEquivalence.) (P: program τ) (d: database τ): 
    proofTheoreticSemantics P d = modelTheoreticSemantics P d
\end{lstlisting}

By the anti-symmetry of the subset operation, it suffices to show that both semantics are a subset of each other.

Our first goal is to show that the proof-theoretic semantics is a subset of the model-theoretic semantics for any fixed program $P$ and database $d$. We actually prove a stronger statement by showing that all elements in the proof-theoretic semantics are in any model. By \cref{lem:modelMTS} the model-theoretic semantics are a model so that the claim follows.

\begin{lemma}[\proofTreeAtomsInEveryModel]
    Let $P$ be a program and $d$ be a database. Let $a$ be a ground atom in the proof-theoretic semantics of $P$ and $d$. Then we have $a \in M$ for all models $M$ of $P$ and $d$.
\end{lemma}
\begin{proof}
    An element is in the proof-theoretic semantics whenever it is the root of a valid proof tree $t$. We prove this by strong induction on the height of $t$ for all trees $t$ and ground atoms $a$.

    There are two cases when $t$ is valid. If it is valid and in the rule case, then there exists a rule $r$ and grounding $g$ such that $r$ is in $P$ and the grounding of $r$, which we call $r'$, has the head $a$ and the body $l$. All elements of $l$ are the root of valid proof trees as well and by the definition of the height function have a smaller height. By the induction hypothesis therefore all elements of $l$ are in $M$. Since $r'$ is the result of applying a grounding to a rule from $P$, $r'$ must be true in $M$. Therefore $a$ is also in $M$.

    In the database case, the root is an element of the database. Any element of the database must be in any model by definition. 
\end{proof}

For the back direction, it suffices to show that the proof-theoretic semantics are a model as well by \cref{lem:leastModel}.

\begin{lemma}[\proofTheoreticSemanticsIsModel]\label{lem:PTSModel}
    Let $P$ be a program and $d$ be a database. Then the proof-theoretic semantics of $P$ and $d$ is a model for $P$ and $d$.
\end{lemma}
\begin{proof}
    As any element from the database $d$ has a valid proof tree, the database is contained in the proof-theoretic semantics. 

    We need to prove that all rules from $ground(P)$ are true in the proof-theoretic semantics. Let $r$ be such a rule and suppose that every element of $body(r)$ is in the proof-theoretic semantics. Therefore there exists a list of trees $t_1, \dots ,t_n$ such that all trees are valid and the list $root(t_1), \dots ,root(t_n)$ equals the body of $r$. Then we can build a new tree with the root $head(r)$ and the children $t_1 \dots t_n$. This tree is valid because all subtrees are valid and the root and its children are the instance of a ground rule of $P$. Therefore also $head(r)$ is in the proof-theoretic semantics and $r$ is true.
\end{proof}

We expand a bit on the proof above. The lemma we use to get the valid proof tree for $head(r)$ is called \createProofTreeForRule. We know that all elements in the body have valid proof trees and need to extract a list of these proof trees. We show in the lemma \getTreeHelper a more general property from which this follows.

\begin{lemma}[\getTreeHelper]\label{lem:getTreeHelper}
    Let $A$ and $B$ be types. Let $l$ be a list of type $A$ and $S$ be a finite set of type $A$. Let $f$ be a function from $B$ to $A$ and $valid$ a property of elements of type $B$. If all elements from $l$ are in $S$ and for any element $a$ in $S$ there exists an element $b$ such that $f(b) = a $ and $b$ is valid, then there exists a list $l'$ such that mapping $l'$ with $f$ yields $l$ and all elements of $l'$ fulfill the isValid predicate.
\end{lemma}

Before proving the statement, we explain how we want to use this. $A$ is supposed to be the ground atoms and $B$ is supposed to be the proof trees. The function $f: B \to A$ is the root function, $l$ is the body of the rule $r$ and $S$ is the finite set of the body elements. We use the set as we will use induction on $l$ so that $l$ will not always be the body of a rule in the proof. If we want to show that the head is in the proof-theoretic semantics, we already know that every atom $a$ in the body has a valid proof tree whose root is $a$. Then we get the list of proof trees we can use as the children for the rule creation.

\begin{proof}[Proof of \cref{lem:getTreeHelper}]
    We prove this by structural induction on $l$. If $l$ is empty then we can simply use the empty list for $l'$ that fulfills the desired properties.

    If $l$ has the shape $hd::tl$, then we can get a $hd_b$ element for $hd$ since $hd$ in $S$. By the properties of $S$, $hd_b$ is valid and is mapped to $a$ via $f$. Any element in $tl$ is still in $S$ so that the induction hypothesis provides us a list $tl'$ that maps via $f$ to $tl$ with only valid members. Then the list $hd_b::tl'$ is the witness for $l'$.
\end{proof}

This concludes the back direction and we finish the proof of the equivalence of the semantics and conclude this chapter.

\begin{theorem}[\SemanticsEquivalence]\label{trm:semanticsEquiv}
    For any program $P$ and database $d$ the model-theoretic and the proof-theoretic semantics of $P$ and $d$ coincide.
\end{theorem}