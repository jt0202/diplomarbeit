\section{Evaluation}\label{sec:eval}

In the previous sections we proved the correctness the algorithms to check the soundness and completeness of datalog reasoning results. Now, we are interested in the practicability of these algorithms on actual data. We combined these algorithms into a command line tool that takes a file consisting of the problem and the certificates and tells us whether the result is correct according to the certificate. 

\subsection{Input format}

The input format is JSON-based because Lean offers already direct support for JSON. Similarly, as we were able to derive decidable equality or inhabitedness, we can also derive functions that convert Lean objects to JSON objects or try to create a Lean object from a JSON object.

We can define mock terms similar to \term but with the variables and constants as simple strings. Lean knows how to read and write strings into JSON hence we can derive the Json methods.

\begin{lstlisting}
inductive (.\mockTerm.)
| constant: String → mockTerm
| variable: String → mockTerm
deriving DecidableEq, Lean.FromJson, Lean.ToJson, Repr
\end{lstlisting}

Using this type we can similarly as to \atom define \mockAtom. In contrast to real atoms, we do not require a proof that the number of terms matches the arity of the predicate symbol as encoding such a proof is difficult and we have no information about the arity. The symbol is again just a string.

\begin{lstlisting}
structure (.\mockAtom.) where
  (symbol: String)
  (terms: List mockTerm)
deriving DecidableEq, Lean.FromJson, Lean.ToJson, Repr
\end{lstlisting}

Mock atoms form mock rules similarly as atoms form rules and a program is simply a list of mockRules. Lists are a basic feature of the Json decoder which allows us to get the from a json file. 

\begin{example}
    The program 

    \begin{equation}
        \begin{split}
            &P = \{  \\
            &T(?x,?y) \leftarrow E(?x,?y), Q(a).\\
            \}
        \end{split}
    \end{equation}

    is represented as following in json:

    \begin{lstlisting}
        "program": [
        {
            "head": {
                "symbol": "T",
                "terms": [
                    {
                        "variable": "?x"
                    },
                    {
                        "variable": "?y"
                    }
                ]
            },
            "body": [
                {
                    "symbol": "E",
                    "terms": [
                        {
                            "variable": "?x"
                        },
                        {
                            "variable": "?y"
                        }
                    ]
                },
                {
                    "symbol": "Q",
                    "terms": [
                        {
                            "constant": "a"
                        }
                    ]
                }

            ]
        }]
    \end{lstlisting}
\end{example}

Afterwards we go twice through the program. In the first run, we collect all the predicate symbols and their arities (\parsingArityHelper) into a list and report an error if a predicate symbol is used in multiple atoms with different amounts of terms. Using such the list we can construct a signature (\parsingSignature). We use for constants and variables simply the set of string as types and for predicate symbols the subset of strings that occured as symbols. This choices allows us to directly inherit the requirements for the signature elements such as decidable equality or hashability. 

In the second run, we then transform every mock object into the corresponding datalog object of the previously created signature. 

The second part is the input file is either a list of trees or a graph. For these we define again mock objects and transform them after we transformed the program.

\begin{lstlisting}
inductive jsonTree (A: Type)
| node (label: A) (children: List (jsonTree A))
deriving Lean.FromJson, Lean.ToJson

-- graph validation
structure mockEdge where
  (vertex: mockAtom)
  (successors: List (mockAtom))
deriving DecidableEq, Lean.FromJson, Lean.ToJson

structure mockGraph where
  (edges: List mockEdge)
deriving Lean.FromJson, Lean.ToJson
\end{lstlisting}

Additionally, there are two command line options that can be set. Firstly, the option \textit{-g} specifies that the input file as a graph instead of a list of trees which is the default option. Secondly, we tell the program with \textit{-c} to also use the \modelChecker to check for completeness.

The file does not include a database yet because these databases are often very large in practice which requires more work to replicate in Lean. All evaluations are done with a mock database which assumes that any leaf of a tree is in the database and that the database is always contained in the model during the model checking. 


\subsection{Results}

In this section we want to evaluate the program in practice. We are interested in the feasibility of our approach to verify proof trees and to check a complete result. Additionally, we want to compare the tree verification with the graph-based verification.

We will use three kinds of datalog programs to test our approach:

\begin{enumerate}
    \item We will use the transitive closure programs we considered in this work multiple times. The exact program use the transitive predicate once in the body.
    \begin{equation}
        \begin{split}
            Trans(?x, ?y) &\leftarrow Edge(?x, ?y). \\
            Trans(?x, ?z) &\leftarrow Edge(?x, ?y),  Trans(?y, ?z). 
        \end{split}
    \end{equation}

    This program can be used in on different directed graphs and may encode some kind of reachability problem. We create the graphs in a python script using networkx's \lstinline|gnm_random_graph| which uniformly selects a graph from the graphs for a given number of vertices and edges. Selecting different values for these numbers allows us to check the feasibility of both use cases.

    \item We will reuse the program from \cref{ex:treeGraph} on chains of different lengths. We have theoretically analyzed that the proof trees are exponentially larger than the corresponding proof graphs and want to see if the algorithms also respect that in practice.
    
    \item Finally, we will use a large example from practice. The problem deals with reasoning in the OWL EL profile of the web ontology language OWL whose transformation to datalog is described in \cite{ELK}. As the database we reuse the medical ontology GALEN which is also used in the original paper. The ontology is preprocessed to csv files and leads to around 1.8 million derived atoms.
\end{enumerate}

We will use the datalog engine Nemo\cite{Nemo} to evaluate these examples. Nemo allows us to specify multiple facts as a file and ask for their derivations. This is returned in a machine-readable json format which allows us to transform this and the program into the input file format described in the previous section.

Any other datalog engine that returns proof trees or graphs can also be used as long as such a program exists to convert it into the input format. This would also be possible with Soufflé\cite{Souffle} but the proof trees there are only given in an ASCII art style which complicates the parsing.

The experiments run on a modern laptop with an AMD Ryzen 7 processor, 8 GB of RAM using Ubuntu in the Windows subsystem for Linux. We will also display the time used by Nemo for each tasks as a comparision. We believe that it is fine if the verification takes a bit longer than the computation but it should not takes hours for a task that Nemo can solve in seconds. As there is currently no alternative program capable of verifying datalog reasoning results this is the only other time available for comparision.

\begin{figure}
\begin{tabular}{llrrrrrrr}
    &  & Number of nodes & \multicolumn{2}{r}{Nemo time} & \multicolumn{2}{r}{Preparation time} & \multicolumn{2}{r}{Validation time} \\
    &  & mean & mean & std & mean & std & mean & std \\
   Type & Size &  &  &  &  &  &  &  \\
   \multirow[c]{3}{*}{graph} & 10 & 18.00 & 0.03 & 0.01 & 0.03 & 0.01 & 0.05 & 0.06 \\
    & 15 & 28.00 & 0.02 & 0.00 & 0.03 & 0.00 & 0.02 & 0.00 \\
    & 20 & 38.00 & 0.02 & 0.00 & 0.03 & 0.00 & 0.03 & 0.00 \\
   \multirow[c]{3}{*}{tree} & 10 & 1022.00 & 0.03 & 0.01 & 0.07 & 0.01 & 0.03 & 0.00 \\
    & 15 & 32766.00 & 0.02 & 0.00 & 2.71 & 0.09 & 0.16 & 0.00 \\
    & 20 & 1048574.00 & 0.02 & 0.00 & 207.66 & 3.98 & 4.38 & 0.20 \\
\end{tabular}
\caption{Results for scenario 2}
\end{figure}

\begin{figure}
    \begin{tabular}{lllrrrrrr}
        &  &  & \multicolumn{2}{r}{Number of nodes} & \multicolumn{2}{r}{Preparation time} & \multicolumn{2}{r}{Validation time} \\
        &  &  & mean & std & mean & std & mean & std \\
       Type & Completeness & Density &  &  &  &  &  &  \\
       \multirow[c]{8}{*}{graph} & \multirow[c]{4}{*}{False} & 0.010000 & 749.10 & 234.33 & 0.25 & 0.12 & 0.03 & 0.00 \\
        &  & 0.050000 & 10395.20 & 81.38 & 17.63 & 0.38 & 0.17 & 0.01 \\
        &  & 0.100000 & 10990.00 & 0.00 & 16.91 & 0.25 & 0.17 & 0.02 \\
        &  & 0.300000 & 12970.00 & 0.00 & 18.37 & 0.26 & 0.18 & 0.01 \\
        & \multirow[c]{4}{*}{True} & 0.010000 & 749.10 & 234.33 & 0.25 & 0.12 & 0.05 & 0.01 \\
        &  & 0.050000 & 10395.20 & 81.38 & 17.63 & 0.38 & 15.65 & 0.67 \\
        &  & 0.100000 & 10990.00 & 0.00 & 16.91 & 0.25 & 33.04 & 0.82 \\
        &  & 0.300000 & 12970.00 & 0.00 & 18.37 & 0.26 & 114.65 & 6.41 \\
       \multirow[c]{8}{*}{tree} & \multirow[c]{4}{*}{False} & 0.010000 & 5996.80 & 3568.63 & 1.46 & 1.03 & 0.04 & 0.01 \\
        &  & 0.050000 & 59709.40 & 714.58 & 235.27 & 4.16 & 0.37 & 0.01 \\
        &  & 0.100000 & 44814.57 & 92.01 & 179.52 & 1.47 & 0.32 & 0.01 \\
        &  & 0.300000 & 34062.00 & 1.41 & 170.25 & 0.97 & 0.28 & 0.02 \\
        & \multirow[c]{4}{*}{True} & 0.010000 & 5996.80 & 3568.63 & 1.46 & 1.03 & 0.14 & 0.10 \\
        &  & 0.050000 & 59709.40 & 714.58 & 235.27 & 4.16 & 26.58 & 0.80 \\
        &  & 0.100000 & 44814.57 & 92.01 & 179.52 & 1.47 & 39.17 & 2.03 \\
        &  & 0.300000 & 34062.00 & 1.41 & 170.25 & 0.97 & 105.80 & 1.97 \\
       \end{tabular}
\caption{Results for scenario 1}       
\end{figure}