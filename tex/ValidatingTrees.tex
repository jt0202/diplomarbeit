\section{Validating proof trees}\label{sec:valTree}

After introducing the problem and modelling in Lean, we now describe the algorithm to verify a solution partially. We focus in this section on the soundness by verifying a given proof tree. In the previous section we introduced the following characterization for valid proof trees:

\begin{lstlisting}
    def isValid(P: program τ) (d: database τ) (t: proofTree τ): 
    Prop :=
    match t with
    | proofTree.node a l => 
    ( ∃(r: rule τ) (g:grounding τ), 
        r ∈ P ∧ 
        ruleGrounding r g = groundRuleFromAtoms a (List.map root l)
        ∧ l.attach.All₂ (fun ⟨x, _h⟩ => isValid P d x)) 
    ∨ (l = [] ∧ d.contains a)
\end{lstlisting}

This is a disjunction so we need for both disjuncts procedures to decide if they are true.
The second part of this disjunction consists of a database check and an easy check of list emptyness. Both can be done in a straightforward way.
The first part is more interesting. Since we use there existential quantifiers, this is not computable and have to implement a function for this. While we can simply iterate over the program to check for the existance of an $r$, the number of groundings might be exponential or even infinite. Instead of using groundings, we want to use some more sophisticated to check this which we introduce next.


\subsection{Substitutions}
    A grounding is function from variables to constants. This means we always need to specify for every variable a constant that it is mapped to. This was good in the definitions to ensure that we always get a ground atom, but raises in the unification case problems as the following example demonstrates.

    \begin{example}
        Suppose we want ask whether we can unify the list of terms $l_1 = [?x, ?y]$ with the list of constants $l_2= [a,b]$, i.e. we look for a function $f: V \to C$ such that mapping every element of $l_1$ with $f$ yields $l_2$.

        We start by trying to unify $x$ and $a$. If we use groundings, we might use this function $g = x \mapsto a, y \mapsto a, z \mapsto a$.

        Now we want to use this result and match another term $y$ with the constant $b$. The variable $y$ is already mapped to a different constant, but we cannot say whether this is due to a previous matching process or simply because we needed to define a value for every input.         
    \end{example}
    
    One solution might be to use a special constant symbol that we map variables to that are really unmapped for now.
    Instead, we want to use substitutions that were already introduced in \cite{datalogCoq}. A substitution is a partial mapping from variables to constants. We implement this by mapping to an Option of constant.

    \begin{lstlisting}
    def (.\substitution.) (τ: signature):= τ.vars → Option (τ.constants)
    \end{lstlisting}

    This allows us to only specify what is necessary. We call the substitution that maps any variable to none the empty substitution.
    
    If we apply a substitution to a term and this term is a constant, we do not change the term. If the term is a variable and the substitution does not map the variable to none we replace the variable with the result of the substitution.

    \begin{lstlisting}
    def (.\applySubstitutionTerm.) (s: substitution τ) (t: term τ): term τ :=
    match t with
    | term.constant c => term.constant c
    | term.variableDL v => 
        if p: Option.isSome (s v) 
        then term.constant (Option.get (s v) p) 
        else term.variableDL v
    \end{lstlisting}

    Similar to groundings we can extend this to atoms (\applySubstitutionAtom) and rules (\applySubstitutionRule). As we no longer replace all variables by constants, this only results in atoms instead of ground atoms.

    The main result we want to prove is the following.

    \begin{lstlisting}
    theorem groundingSubstitutionEquivalence 
        (r: groundRule τ) (r': rule τ):
        (∃ (g: grounding τ), ruleGrounding r' g = r) ↔ 
        (∃ (s: substitution τ), applySubstitutionRule s r'= r)
    \end{lstlisting}

    This allows us to replace the grounding check by a substitution check, when trying to validate trees and by this we can bypass the problems that were illustrated in the example above. 

    For the forward direction, we want to find an equivalent substitution for every grounding. We can do this by mapping every variable to the the same value of the grounding and place this in the some constructor to obtain an element of the Option type.

    \begin{lstlisting}
    def (.\groundingToSubstitution.) (g: grounding τ): substitution τ
        := fun x => Option.some (g x)
    \end{lstlisting}

    We have to prove that these are actually equivalent. We defined in the previous section a coercion from ground atoms to atoms. We can also coerce constants to terms by the \lstinline|term.constant| constructor which enables to us to use an equality in the following lemma.

    \begin{lemma}[\groundingToSubsitutionEquivTerm]
        Let $t$ be a term and $g$ be a grounding. Then the grounding of $t$ by $g$ is equal to the application of
        
        \lstinline|groundingToSubstitution g| to $t$.
    \end{lemma}
    \begin{proof}
        If $t$ is a constant, then both elements will simply return $t$.

        If $t$ is a variable $v$, then the term grounding by $g$ will return $g(v)$. By the definition of \lstinline|groundingToSubstitution| all variables $v'$ return a some type which contains $g(v')$. Therefore the application replaces $v$ by $g(v)$ and both results are equal. 
    \end{proof}

    Using this result we can extend this equality to the atom level 
    
    (\groundingToSubsitutionEquivAtom), because in both cases only the terms change by the application of the functions of the previous lemma. Finally, we can extend this to the rule level (\groundingToSubsitutionEquivRule).

    For the back direction, we need an additional property illustrated by the following example.
    \begin{example}
        Consider the program $\mathcal{P} = \{P \leftarrow, Q \leftarrow P\}$ and the signature $C = \emptyset$, $V = \{?x,?y,?z \}$ and $P = \{p,q\}$

        Any rule in $\mathcal{P}$ is already a ground rule and there exists a substitution, the empty substitution that maps all variables to none, so that the rule is equal to itself as a ground rule.
        
        There is however no grounding that can achieve this. We cannot define a grounding since we have no constant available, but have variables that need to be mapped somewhere. Therefore the equivalence does not hold here.
    \end{example}

    In order for the equivalence to hold we always need at least one constant symbol. There exist at least two possibilities to achieve this in Lean. We could require that the type of constants is inhabited or that it is non-empty. We decided to use the first as the inhabited class offers directly a constant, the default value, whereas the class non-empty only proves that such an element exists and requires the axiom of choice to extract it.

    \begin{lstlisting}
        def (.\substitutionToGrounding.) [ex: Inhabited τ.constants] 
        (s: substitution τ): grounding τ :=
        fun x => 
        if p:Option.isSome (s x) 
        then Option.get (s x) p 
        else ex.default
    \end{lstlisting}

    \begin{contexample}
        If we add the fresh symbol $a$ to $C$, we can use the function $f: V \to C, v \mapsto a$. This will not cause any problems during the verification of a proof tree. While it increases the number of groundings it will not result in any match if used, because it does not occur in the proof tree.
    \end{contexample}

    This is similar to the Herbrand base where we also add a constant symbol, if no constant is present.

    For the back direction, we prove again that it is equivalent on terms and then the atom and rule case easily follow.

    \begin{lemma}[\substitutionToGroundingEquivTerm]
        Let $\tau$ be a signature that contains at least one constant symbol. For any substitution $s$, term $t$ and constant $c$ such that applying $s$ to $t$ yields $t$, also grounding $t$ by \lstinline|substitutionToGrounding| yields $c$.
    \end{lemma}
    \begin{proof}
        If $t$ is a constant, then it must be equal to $c$ and neither the grounding nor the substitution change the term.

        If $t$ is a variable $v$, then $s(v)$ must be $c$ in order to be equal to $c$. Therefore $s(v)$ is defined and \lstinline|substitutionToGrounding| replaces $v$ by the same value, so that the equality holds as well.
    \end{proof}

    In the end, we obtain the desired theorem with the additional requirement on the set of constants.

    \begin{theorem}[\groundingSubstitutionEquivalence]\label{trm:groundingSubstitutionEquivalence}
        Let $\tau$ be a signature that contains at least one constant symbol. Then for any $\tau$ rule $r'$ and ground rule $r$ we have that there exists a grounding $g$ such that grounding $r'$ by $g$ yields $r$ iff there exists a substitution $s$ such that applying $s$ to $r'$ yields $r$.
    \end{theorem}

    When introducing substitutions, we had the goal to only add what is needed to a substitution and usually we want the smallest possible substitution. In order to formalize this, we want to define a partial order on substitutions, that is denoted by $\subseteq$

    Firstly, we define the substitution domain of a substitution as the set of variables for which the substitution is defined. 

    \begin{lstlisting}
    def substitution_domain (s: substitution τ): Set (τ.vars) := 
        {v | Option.isSome (s v) = true}
    \end{lstlisting}

    A substitution $s_1$ is then a subset of a substitution $s_2$, if both substitutions agree on the substitution domain of $s_1$. Outside of this $s_1$ is never defined, whereas $s_2$ might be, so that we view $s_1$ as smaller.

    \begin{lstlisting}
    def substitution_subs (s1 s2: substitution τ): Prop :=
    ∀ (v: τ.vars), v ∈ substitution_domain s1 → s1 v = s2 v
    \end{lstlisting}

    This relation is by defintion reflexive (\substitutionsubsrefl). It is also anti-symmetric (\substitutionsubsantisymm). Since $s_1 \subseteq s_2$ anywhere where $s_1$ is defined $s_2$ is defined as well and has the same value. Since $s_2 \subseteq s_1$ anywhere where $s_2$ is defined the same holds, so that they have the same substitution domain and on it the same values. By the principle of function extensionaliy both functions are equal.

    Lastly, it is also transitive (\substitutionsubstrans), so it is an instance of a partial order.

\subsection{Unification}

We know that instead of finding a grounding, it suffices to find a substitution. Now we want to describe an algorithm that tells us whether the ground rule that is formed from a vertex of the proof tree and its children is in the ground program. For this we take inspiration from the unification problem of first-order logic.

In the unification problem we are given a set of equations between first-order terms and are required to present the most-general unifier.

Our problem is similar. The equations will not be between terms, but between an object and a ground object of the same corrosponding type and we require a substitution that solves all equations and is minimal in our subset relation.

An algorithm to solve the first-order unfication problem is the algorithm of Martelli and Montanari \cite{MartMont} and is depicted below:
\begin{algorithm}
    \caption{Algorithm of Martelli and Montanari}
\begin{algorithmic}
    \While {There exists some equation for which a transformation is possible}
    \State Pick this equation $e$ and do one of the following steps if applicable
    \begin{enumerate}
        \item If $e$ is of the form $t = t$, then delete this equation from the set.
        \item If $e$ is of the form $f(t_1, .., t_n) = f(s_1,.., s_n)$, then delete $e$ and add $n$ new equations of the form $t_i = s_i$
        \item If $e$ is of the form $f(t_1, .., t_n) = g(s_1,.., s_m)$ with $g \neq f$, then stop and reject.
        \item If $e$ is of the form $f(t_1,..,t_n) = x$ for a variable $x$ and delete $e$ and add an equation with the swapped order to the set
        \item If $e$ is of the form $x=t$ for some variable $x$, then check if x occurs in t. If it does, then stop and reject. If not map all $x$ to $t$ in the set.
    \end{enumerate}
    \EndWhile
\end{algorithmic}
\end{algorithm}

This algorithm offers a good starting point for our own algorithm, but we certain transformation can't occur in the limited syntactic form we operate in. Additionally, we want to output a substitution instead of just answering whether a substitution exists. It is sufficient to do it here, but will later be important. Instead of mapping all $x$ to $t$ as done there in step 5, we will add $x\mapsto t$ to a substitution that is presented as an input. If a variable occurs on the left side, we will check whether it is already in the domain of the substitution and if so check if its current value is consistent with the right side.
As function symbols apart from constant symbols are not allowed, we can simplify steps 2 and 3, as we never add new equations and instead only check if the constant symbol matches. Finally, as the one side of the equation is always a ground object there will never be a variable on this side, so that we do not have to swap the equation as in step 4.

We will start with matching a term to a constant with the following algorithm.

\begin{lstlisting}
    def (.\matchTerm.) (t: term τ)(c: τ.constants) (s: substitution τ):
    Option (substitution τ) :=
    match t with
    | term.constant c' =>
        if c = c'
        then Option.some s
        else Option.none
    | term.variableDL v =>
        if p:Option.isSome (s v)
        then  if Option.get (s v) p = c
            then
                Option.some s
            else
                Option.none
        else extend s v c
\end{lstlisting}

We are given a term $t$, a constant $c$ and a current substitution $s$ and want to return the minimal substitution $s'$ so that $s \subseteq s'$ and applying $s'$ to $t$ will make it equal to $c$ or none if no such $s'$ exists.

This is done by case distinction. If $t$ is a constant, then we either return $s$ if $t$ is equal to $c$, or return none as two different constants can not be unified by a substitution. If $t$ is variable, we check if $t$ is in the domain of $s$. If it is already defined we check if the value matches the required value. If it is not defined we extend $s$ with the new mapping $v \mapsto c$.
Formally extend is defined in the following way:

\begin{lstlisting}
    def extend (s: substitution τ) (v: τ.vars) (c: τ.constants) :
        substitution τ 
    := fun x => if x = v then Option.some c else s x
\end{lstlisting}

We know formally prove the correctness of this algorithm. The first result is that if \texttt{matchTerm} returns a substitution $s'$ that $s'$ is indeed a solution, i.e. that applying $s'$ to $t$ results in $c$ and that $s'$ is an extension of $s$

\begin{lstlisting}
    lemma matchTermFindsSolution (t: term τ) (c: τ.constants) 
    (s: substitution τ) (h: Option.isSome (matchTerm t c s)): 

    applySubstitutionTerm (Option.get (matchTerm t c s) h) t = c 
    ∧ s ⊆ (Option.get (matchTerm t c s) h)
\end{lstlisting}
\begin{proof}
The proof is done via case distinction. Suppose firstly that $t$ is a constant $c'$. Since matchTerm returned a substitution we must have that $c$ and $c'$ are the same constant and therefore $s'$ is $s$. Applying a substitution to a constant does not change it, so $s' t = s' (c') = c' = c$. Additionally since $\subseteq$ is a linear order and $s' = s$, we have that $s \subseteq s'$

Now we assume that $t$ is a variable $v$. Now we do another case distinction on whether $s v$ is defined or not. If it is defined, $v$ must already be mapped to $c$ and we return $s$ as this is a solution as seen previously. If it would be mapped to something else, then matchTerm would return none, which would be in violation to our assumptions.
If it is not defined, we use extend. After that $v$ is mapped to $c$, so that $s' t$ will be equal to $c$. Now we finally have to show that $s \subseteq$ extend $s$ $v$ $c$. We only change the value of $v$. Since $v$ was not defined earlier, for any variable in the domain of $s$, $s$ and extend $s$ $v$ $c$, so that it is fulfilled.
\end{proof}

We have proven so far the matchTerm returns a solution, but it might not be a minimal solution. When we want to match atoms with ground atoms, we need to match a list of terms with a list of constants. There it is important that the returned substitution is indeed minimal to conclude whether a solution exists as the following example shows.

\begin{example}
    Consider the list of terms $l_1 = [x, y, x]$ with the variables $x$ and $y$ and the list of constants $l_2 = [a,b, c]$. We want to find a substitution that we can apply to $l_1$ to gain $l_2$ if possible. We start with the empty substitution and first want to match the first elements of $l_1$ and $l_2$. If we receive a solution $s$, then we continue with the next elements of $l_1$ and $l_2$, but this time the matching extends $s$ instead of the empty substitution.

    Now suppose the procedure $P_1(t,c, s)$ that takes a term, a constant and a substitution does not always return a minimal solution. So it might return for $x$, $a$ and the empty substitution the substitution $s = x \mapsto a, y\mapsto a$.

    Now we again call $P_1$ with $y$, $b$ and $s$. $P_1$ will not return anything, because $y$ is already mapped to something else. From this fact we cannot conclude that there exists no solution at all however. In fact, the non-minimality of the results of $P_1$ prevents this reasoning.

    If we have a second procedure $P_2(t,c, s)$ that always returns the minimal solution we solve the matching process for the first two list elements of each list to return $s' = x \mapsto a, y \mapsto y$. Now we want to match $x$ with $c$ and $P_2$ will return none. We can conclude that no solution exists since any substitution from $P_2$ is minimal. If there exists a solution to the list then $l_2$, it necessarily must match the first to elements of both lists. Since $s'$ is the minimal solution of a process that started with the empty substitution and always returned minimal solution, any solution to the list must extend $s'$. Therefore it must agree on the domain of $s'$ and therefore it must map $x$ to $a$ and therefore no solution can exist.

\end{example}

\begin{lstlisting}
    lemma matchTermFindsMinimalSolution' (t: term τ) 
    (c: τ.constants) (s: substitution τ) 
    (h: Option.isSome (matchTerm t c s)): 
    
    ∀ (s': substitution τ),(s ⊆ s' ∧ applySubstitutionTerm s' t = c)
        → (Option.get (matchTerm t c s) h) ⊆ s' :=
\end{lstlisting}
\begin{proof}
This is again done via case distinction on the type of $t$. If $t$ is constant, then $s'$ must be equal to $s$. For any $s^\ast$ with $s \subseteq s^\ast \land s^\ast t = c$ we have b that $s' \subseteq s^\ast$ by the assumption of the property of $s^\ast$

Now we consider the case of $t$ being a variable $v$ and do a case distinction whether $s v$ is defined. If it was already defined, then $s'$ must again be equal to $s$, so that the claim is fulfilled by the argument above.
If $s v$ was not defined, we have to show that extend $s$ $v$ $c$ is a subset of any such $s^\ast$. We assume for a contradiction that this is not the case. Then there must be a variable in the domain of extend $s$ $v$ $c$ such that extend $s$ $v$ $c$ and $s^\ast$ differ. Suppose this variable is $v$. Then $s^\ast$ would either not be defined for $v$ or map $v$ to some other constant $c'$. In both cases $s^\ast v \neq c$, so that $s^\ast$ would not be a solution and we would have reached a contradiction.
If it is some other variable $v'$, then the value of extend $s$ $v$ $c$ is simply the value of $s$. Since $s^\ast$ maps $v$ to a different value compared $s$, $s$ would not be a subset of $s^\ast$ and we have reached another contradiction.
\end{proof}

So we know that if matchTerm returns a substitution then it is a minimal solution. We additionally have to prove that if matchTerm does not return a substitution that then no solution exists.

\begin{lstlisting}
    lemma matchTermNoneImpNoSolution (t: term τ)
        (c: τ.constants) (s: substitution τ)
        (h: Option.isNone (matchTerm t c s)):
    
    ¬ (∃(s': substitution τ), s ⊆ s'∧applySubstitutionTerm s' t = c)
\end{lstlisting}
\begin{proof}
This is again done via case distinction on the type of $t$. If $t$ is a constant $c'$, then $c'$ must be different from $c$, so that matchTerm returns none. Then no substitution can map $t$ to c.

If $t$ is a variable $v$, then $s v$ must be defined and mapped to a different value compared to $c$. Then again no such $s'$ can exist. If $s$ would be a subset of $s'$, then $s'$ would not unify $t$ with $c$ and if $s'$ would unify $t$ with $c$ then $s$ would not be a subset of $s'$.
\end{proof}

After proving the correctness for terms we now want to move up to atoms. Unfortunately, we cannot use recursion directly on the term list of an atom. An atom requires a proof that the length of the list is equal to the arity of the relation symbol, which fails when we do recursion on the list. Therefore we first establish a new procedure that matches a list of terms with a list of constants, if possible.

\begin{lstlisting}
    def matchTermList (s: substitution τ) (l1: List (term τ))
        (l2: List (τ.constants)): Option (substitution τ) :=
    match l1 with
    | List.nil => some s
    | List.cons hd tl =>
        match l2 with
        | List.nil => none
        | List.cons hd' tl' =>
        let s' := matchTerm hd hd' s
        if p: Option.isSome s'
        then matchTermList (Option.get s' p) tl tl'
        else none
\end{lstlisting}

Here we are given as previously a substitution as an input with the two lists. For the correctness it is required that both lists have the same length, but this is the case for atoms. If the first list is empty we return the substitution. If instead it has a first element and the second list has as well a first element, we match these elements using matchTerm and if this results in a solution, we return the result of matchTermList with the remaining lists and the resulting substitution.

As previously, we have to prove the correctness of this algorithm. We again want to show that the algorithm returns the minimal solution iff it exists. We require for these results that both lists are the same length. If the list of constants is longer than the list of terms, the \texttt{matchTermList} function may return a solution eventhough the lists will never be equal. As we only want to use this to match atoms, this is however not a problem. No subsititution can change the symbol, so that we will only try to match atoms with ground atoms that have the same symbol. The symbol determines the number of terms so that both lists will have the same length.

\begin{lstlisting}
    lemma matchTermListFindsSolution (s: substitution τ)
    (l1: List (term τ)) (l2: List (τ.constants))
    (len: l1.length = l2.length)
    (h:Option.isSome (matchTermList s l1 l2)):
        List.map (applySubstitutionTerm (Option.get (matchTermList s l1 l2) h)) l1 
        = List.map term.constant l2 
        ∧ s ⊆ (Option.get (matchTermList s l1 l2) h ) :=
\end{lstlisting}
\begin{proof}
    We prove this by induction on $l_1$ for arbitrary $s$ and $l_2$.
    In the base case $l_1$ is the empty list. Since both lists have the same length $l_2$ must also be the empty list. matchTermList then returns $s$. Applying this to an empty list returns an empty list. Therefore the base case is complete.

    In the induction step we have that $l_1$ is of the form $hd::tl$ and we can similarly assume that $l_2$ is of the form $hd'::tl'$ and that $tl$ and $tl'$ have the same length by our assumption. Since matchTermList returned a substitution, matchTerm $hd$ $hd'$ also must return a substitution $s^\ast$.
    We then use this as an input to gain $s'$ from matchTermList $s^\ast$ $tl$ $tl'$. By the induction hypothesis $s^\ast \subseteq s'$ and applying $s'$ to $tl$ results in it being equal to $tl'$. To show that both lists are equal, we just have to show that after applying $s'$ the heads will be equal. We know that applying $s^\ast$ to $hd$ will result in it being equal to $hd'$. Since $s^\ast \subseteq s'$ and our previous result that if a substitution maps a term to a constant then extension of this substitution will also map the term to the same constant, we have this.
    Lastly, we have to show that $s \subseteq s'$. From the correctness proof of matchTerm we know that $s \subseteq s^\ast$ and from the induction hypothesis we know that $s^\ast \subseteq s'$. Since $\subseteq$ is transitive, the result follows.
\end{proof}

After proving that it is a solution, we prove that the solution is minimal.

\begin{lstlisting}
    lemma matchTermListFindsMinimalSolution (s: substitution τ)
    (l1: List (term τ)) (l2: List (τ.constants)) 
    (len: l1.length = l2.length) 
    (h: Option.isSome (matchTermList s l1 l2)):
    ∀ (s': substitution τ), 
        List.map (applySubstitutionTerm s') l1 = List.map term.constant l2
        ∧ s ⊆ s' → (Option.get (matchTermList s l1 l2) h ) ⊆ s' :=
\end{lstlisting}
\begin{proof}
    We prove this again via induction on $l_1$ for arbitrary $l_2$ and $s$. If $l_1$ is empty, we return $s$ and the claim is true by assumption.

    In the induction step we have that $l_1$ has the form $hd::tl$ and we can assume that $l_2$ has the form $hd'::tl'$ and that $tl$ and $tl'$ have the same length. Additionally, we know that matchTerm $hd$ $hd'$ s returns a substitution $s^\ast$. From the induction hypothesis we know that matchTermList $s^\ast$ tl tl' $\subseteq \hat{s}$ for any substitution $\hat{s}$ that extends $a^\ast$ and maps $tl$ to $tl'$. Since $s^\ast$ is a minimal solution for $hd$ and $hd'$ and $s^\ast$ only extends it, we know that it is a solution for the whole list. We also know from the minimality of $s^\ast$ that $s \subseteq s^\ast$. From the induction hypothesis, we get that $s^\ast \subseteq \hat{s}$. Transitivity tells us that $s \subseteq \hat{s}$ as 
\end{proof}

Finally the negative case that confirms that the return value of none does indeed state that there is no solution.

\begin{lstlisting}
    lemma matchTermListNoneImplNoSolution (s: substitution τ)
    (l1: List (term τ)) (l2: List (τ.constants))
    (len: l1.length = l2.length) 
    (h: Option.isNone (matchTermList s l1 l2)): 
    ∀ (s': substitution τ), s ⊆ s' →
    ¬  List.map (applySubstitutionTerm s') l1 = List.map term.constant l2 :=
\end{lstlisting}
\begin{proof}
    We prove this again via induction on $l_1$ for arbitrary $l_2$ and $s$. If $l_1$ is the empty list, we cannot return none. As the prerequisite is not fulfilled, the statement is correct.

    In the induction step we have that $l_1$ has the form $hd::tl$ and we can assume that $l_2$ has the form $hd'::tl'$ and that $tl$ and $tl'$ have the same length. There are two cases where matchTermList can return none. The first case is when matchTerm $hd$ $hd'$ $s$ returns none. If that is the case there is no $s'$ with $s\subseteq s'$ and applying $s$ to $hd$ will make it equal to $hd'$. Therefore the two lists cannot be equal either and the proof is finished.

    If matchTerm $hd$ $hd'$ $s$ returns a substitution $s^\ast$, then matchTermList $s^\ast$ $tl$ $tl'$ must return none. From the induction hypothesis we know that there is no substitution $s'$ with $s^\ast \subseteq s'$ and applying $s'$ to $tl$ bringing it equal to $tl'$. Since $s^\ast$ is already the minimal solution to match $hd$ with $hd'$ there cannot exist a solution here.
\end{proof}

This can be used to create a matchAtom procedure. We are given an atom and a ground atom and check if the symbols are equal. If they are, we also get that their term lists must be equal as the length of the term list is equal to the arity of the relation symbol. The same symbol implies the same length.
If the symbols are different, we will never unify them.

\begin{lstlisting}
    def matchAtom (s: substitution τ) (a: atom τ) (ga: groundAtom τ):
    Option (substitution τ) :=
        if a.symbol = ga.symbol
        then
            matchTermList s a.atom_terms ga.atom_terms
        else none
\end{lstlisting}

The correctness proofs follow from the proofs of matchTermList since we already established the same length of both lists from the symbol.

Now we can create a \texttt{matchAtomList} function similarly to \texttt{matchTermList} and use this to define a \texttt{matchRule} function. We first try match the head of the rule with the head of the ground rule. If this returns a solution, we use this as the start for matching the bodies. If not, we will not find a solution and return none.

\begin{lstlisting}
    def matchRule (r: rule τ) (gr: groundRule τ):
        Option (substitution τ):=
        let s := matchAtom emptySubstitution r.head gr.head
        if p: Option.isSome s
        then matchAtomList (Option.get s p) r.body gr.body
        else none

\end{lstlisting}

We know prove again that if this returns a substitution then this is a solution and if none is return then there is no solution using our previous results. For both these results we assume that both bodies have the same length, but determining the length of a list can be done in the tree validation process.
We want a statement with the quantifier to combine it with the theorem about the equivalence between groundings and substitutions. We can prove this statement by using the result of \texttt{matchRule} as a witness for the quantifier. For the back direction, we see that this statement implies that a solution exists, which we always find with \texttt{matchRule}

\begin{lstlisting}
    theorem matchRuleIsSomeIffSolution (r: rule τ) (gr: groundRule τ) 
    (len: r.body.length = gr.body.length): 
    Option.isSome (matchRule r gr) ↔ 
    ∃ (s: substitution τ), applySubstitutionRule s r = gr
\end{lstlisting}

We now have a method to replace this quantifier by a computable function and can finally devise the check for tree validation.

\subsection{Tree validation}

We have so far introduced introduced substitutions and have shown a way to decide whether a substitution exists that maps a rule to a ground rule. Now we want to finally show a way to validate trees. As the first step we want to find whether a ground rule $gr$ we gain from the tree is in the ground program, i.e. that there exists a grounding $g$ (or by \cref{trm:groundingSubstitutionEquivalence} a substitution $s$) and a rule $r$ from the program $P$, so that applying $g$ to $r$ yields $gr$. We want to use the \matchRule function defined earlier for this. 
We can simply pass each rule of the program given as a list of rules into this function and stop when \matchRule returns a some object. This works but requires in the worst case to match every rule in the program with a given ground rule. Suppose that the predicate symbol of the head of the given ground rule is $T$. We can safely discard any rule whose head is not an atom with the predicate symbol $T$. This can be generalized into the symbol sequence which is a list of predicate symbols that starts with the predicate symbol of the head and then the predicate symbols of the body atoms in the order the atoms occur in the body.

\begin{lstlisting}
    def (.\symbolSequence.) (r: rule τ): List τ.predicateSymbols := 
        r.head.symbol::(List.map atom.symbol r.body)

\end{lstlisting}

The equality of symbol sequences is a necessary condition for the existence of substitution that matches a rule with a ground rule, as the application of any substitution does not change the symbols and therefore not the symbol sequence. (\symbolSequenceNotEq).

Now we could iterate over the whole program and calculate the symbol sequence for every rule and only start the matchRule process for those whose symbol sequences are equal to the given ground rule. In the worst case we still have to iterate over the whole program. It would be even better to preprocess  the program into a look-up structure that returns a list of rules for a given symbol sequence.

We use a function of the type \lstinline|List τ.predicateSymbols → List (rule τ)| as the look up structure and build it iteratively by adding the first rule of the given program to the right symbol sequence element.

\begin{lstlisting}
    def (.\parseProgramToSymbolSequenceMap.) (P: List (rule τ)) 
    (m: List τ.relationSymbols → List (rule τ)): 
    List τ.relationSymbols → List (rule τ) :=
    match P with
    | [] => m
    | hd::tl =>
        let seq:= symbolSequence hd
        parseProgramToSymbolSequenceMap tl 
            (fun x => if x = seq then hd::(m x) else m x)
\end{lstlisting}

If start this with a function that maps any symbol sequence to the empty list and gain a function $m'$ then for any list of predicate symbols $l$, $m'(l)$ returns exactly those rules in $P$ whose symbol sequence matches $l$. This follows from the following lemma.

\begin{lemma}[\parseProgramToSymbolSequenceMapmem]\label{lem:parseProgramToSymbolSequenceMap}
    Let $P$ be a program and $m$ be a function that maps a list of predicate symbols to the list of rules. Let $m'$ be the result of \lstinline|parseProgramToSymbolSequenceMap P m|. Then for any list of predicate symbols $l$ and rule $r$, we have $r$ is in $m'(l)$ iff $r$ was in $m(l)$ or $r$ is in $P$ and the symbol sequence of $r$ equals $l$.
\end{lemma}
\begin{proof}
    We prove this by induction on the structure of $P$ for arbitrary $m$.

    If $P$ is empty, then $m' = m$ and no rule is a member of $P$ so that the claim follows.

    If $P$ has the structure $hd::tl$, then $m'$ is the result of 

    \begin{lstlisting}
        parseProgramToSymbolSequenceMap tl (fun x => if x = (symbolSequence hd) then hd::(m x) else m x)
    \end{lstlisting}

    Applying the induction hypothesis we see that for any rule $r$ and list $l$, $r$ is in $m'(l)$ iff it is in $tl$ and has the symbol sequence $l$ or was in \lstinline|(fun x => if x = (symbolSequence hd) then hd::(m x) else m x)|

    The only element of $P$ not yet considered was $hd$ and is is either obtained by its symbol sequence or was already there in $m$ so that the proof follows.
\end{proof}

Since at the start $m(l)$ has no member for any $l$, the desired property holds. Now we can use this to check whether a substitution exists.

\begin{lstlisting}
def (.\checkRuleMatch.) (m: List τ.predicateSymbols → List (rule τ)) (gr: groundRule τ): Except String Unit :=
  if List.any (m (symbolSequence gr.toRule)) 
    (fun x => Option.isSome (matchRule x gr)) = true
  then Except.ok ()
  else Except.error ("No match for " ++ ToString.toString gr)
\end{lstlisting}

\begin{lemma}[\checkRuleMatchOkIffExistsRuleForGroundRule]
    Let P be a program, $m$ be the result of \lstinline|parseProgramToSymbolSequenceMap P (fun _  => [])| and $gr$ a ground rule. Then \lstinline|checkRuleMatch m gr| returns ok iff there exists a rule $r$ in $P$ and a grounding $g$ such that grounding $r$ with $g$ yields $gr$.
\end{lemma}
\begin{proof}
    Let $l$ be the symbol sequence of $gr$. Then if checkRuleMatch returns ok, then there exists a rule $r$ in $m(l)$ there exists a grounding $g$ such that grounding $r$ by $g$ yields $gr$. By \cref{lem:parseProgramToSymbolSequenceMap} this rule $r$ is a member of $P$ so the claim is proven.

    If checkRuleMatch returns an error, then we have to show that for rule $r \in P$ and grounding $g$ grounding $r$ by $g$ yields a different ground rule compared to $gr$. If $r$ has the same symbol sequence as $gr$, then it occured in $m(l)$ and since checkRuleMatch returned an error matchRule r gr must return none so that the property holds.

    If $r$ has a different symbol sequence to $gr$ then this property holds as well due to \symbolSequenceNotEq and \cref{trm:groundingSubstitutionEquivalence}.
\end{proof}

This function is almost enough to complete the rule case. We just need to also verify all subtrees. For this we introduce the \lstinline|List.map_except_unit| function that applies a function of the type \lstinline|A → Except B Unit| to a list $l$ until the first error occurs. If no error occurs, then we return unit which is a type that has only one element $()$ and is the place holder because we have to return something.

\begin{lstlisting}
    def (.\Listmapexceptunit.) {A B: Type} (l: List A) 
    (f: A → Except B Unit): Except B Unit :=
    match l with
    | [] => Except.ok ()
    | hd::tl =>
        match f hd with
        | Except.ok () => List.map_except_unit tl f
        | Except.error b => Except.error b
\end{lstlisting}

We can prove by induction that this function returns unit iff $f$ returns unit on all elements of the list $l$ (\ListmapexceptunitIsUnitIffAll).

Now we have the necessary tools to check whether a given proof tree is valid which is done by the \treeValidator. For a tree with the root $a$ and subtrees $l$, we do a case distinction whether $l$ is empty. If $a$ is additionally an element of the database, then we accept because we are in the database case. If not we use checkRuleMatch to check for the rule case. This is returns ok, then we can already accept because there are no subtrees.

If not we can only be in the rule case and first use checkRuleMatch and if this returns ok, then we check all subtrees using the treeValidator again called via \Listmapexceptunit.

\begin{lstlisting}
def treeValidator (m: List τ.predicateSymbols → List (rule τ)) (d: database τ) (t: proofTree τ) : Except String Unit :=
  match t with
  | tree.node a l =>
    if l.isEmpty
    then  if d.contains a
          then Except.ok ()
          else
            match checkRuleMatch m {head:= a, body := List.map root l} with
            | Except.ok _ => Except.ok ()
            | Except.error msg => Except.error msg
    else
      match checkRuleMatch m {head:= a, body := List.map root l} with
      | Except.ok _ => List.map_except_unit l.attach (fun ⟨x, _h⟩ => treeValidator m d x)
      | Except.error msg => Except.error msg
\end{lstlisting}

Using the previous lemmas and an induction over the height of the tree for the recursive calls, we prove the correctness of the treeValidator.

\begin{theorem}[\treeValidatorOkIffIsValid]\label{trm:treeValidator}
    Let P be a program, $m$ be the result of \lstinline|parseProgramToSymbolSequenceMap P (fun _  => [])| and $d$ be a database. For any proof tree $t$ \lstinline|treeValidator m d t| returns ok iff $t$ is valid for $P$ and $d$.
\end{theorem}

\subsection{Validating multiple trees}

As we want to validate the whole result of a datalog program, we will often need many proof trees and a function that can validate them. Additionally, we need to preprocess the program to gain the map from symbol sequences to rules. This is done in the following function.

\begin{lstlisting}
    def validateTreeList (P: List (rule τ)) (d: database τ) 
    (l: List (proofTree τ)) 
    (ruleToString: rule τ → String): Except String Unit :=
    let m:= parseProgramToSymbolSequenceMap P (fun _ => [])
    List.map_except_unit l 
        (fun t => treeValidator m d t  ruleToString)

\end{lstlisting}

Using the properties of \texttt{treeValidator} and \texttt{List.map\_except\_unit}, we can show that this function returns \texttt{ok ()} iff all trees in \texttt{l} are valid. We know that a ground atom $ga$ is in the \texttt{proofTheoreticSemantics} if there exists a proof tree with the root $ga$, so that we can conclude the set of roots of the trees in $l$ is a subset of the semantics. In order to get an iff statement, we also have to include that all trees are valid, because a root preserving permutation of a proof tree will in general not be valid and therefore \texttt{validateTreeList} will report an error, but its root is still in the semantics.

\begin{lstlisting}
    lemma validateTreeListUnitIffSubsetSemanticsAndAllElementsHaveValidTrees 
    (P: List (rule τ)) (d: database τ) (l: List (proofTree τ)) 
    (ruleToString: rule τ → String) : 
    validateTreeList P d l  ruleToString = Except.ok () ↔ 
        {ga: groundAtom τ| ∃ (t: proofTree τ), t ∈ l ∧ root t = ga } ⊆ proofTheoreticSemantics P.toFinset d 
        ∧ ∀ (t: proofTree τ), t ∈ l → isValid P.toFinset d t
\end{lstlisting}

It turns out however that we can do a bit better and prove a stronger statement as the following example shows.
\begin{example}
    Consider the program $P:$
    \begin{align*}
        & A(X, Z) \leftarrow B(U, X, Y, Z). \\
        & B(U, X, Y, Z) \leftarrow C(U, X), D(Z, Y). \\
        & C(a,b). \\
        & D(c,d).
        \end{align*}
    where variables are capital letters. In order to validate the input according the previous lemma we would need the following proof trees.

    \begin{tikzpicture}[every node/.style={circle, minimum size=8mm}, level/.style={sibling distance=40mm/#1}, level distance=20mm]
        \node {D(c,d)};
    \end{tikzpicture}

    \begin{tikzpicture}[every node/.style={circle, minimum size=8mm}, level/.style={sibling distance=40mm/#1}, level distance=20mm]
        \node {C(a,b)};
    \end{tikzpicture}

    \begin{tikzpicture}[every node/.style={circle, minimum size=8mm}, level/.style={sibling distance=40mm/#1}, level distance=20mm]
        \node {B(a, b, c, d)}
            child {node {C(a,b)}}
            child {node {D(c,d)}};
    \end{tikzpicture}

    \begin{tikzpicture}[every node/.style={circle, minimum size=8mm}, level/.style={sibling distance=40mm/#1}, level distance=25mm]
        \node {A(b, d)}
            child {node {B(a, b, c, d)}
            child {node {C(a,b)}}
            child {node {D(c,d)}}};
            
    \end{tikzpicture}

    The proof tree for $A(b,d)$ already contains proofs for all the other elements of the program so that it would be enough to check this single tree.
\end{example}

We can define an element member function for trees in the usual way:

\begin{lstlisting}
    def elementMember (a: A) (t: tree A): Bool  :=
    match t with
    | tree.node a' l => (a=a') ∨
        List.any l.attach (fun ⟨x, _h⟩ => elementMember a x)
\end{lstlisting}
In order for a tree to be valid all subtrees must be valid. A ground atom $ga$ is exactly then a member of a tree $t$ if there is a subtree of $t$ of which $ga$ is the root, so that if a proof tree is valid all elements are a subset of the semantics.

\begin{lstlisting}
    lemma allTreeElementsOfValidTreeInSemantics 
    (t: proofTree τ)  (P: program τ) (d: database τ) 
    (valid: isValid P d t)(ga:groundAtom τ)(mem: elementMember ga t):
        ga ∈ proofTheoreticSemantics P d :=
\end{lstlisting}

This allows us to establish the alternative property of \texttt{validateTreeList}

\begin{lstlisting}
    lemma validateTreeListUnitIffSubsetSemanticsAndAllElementsHaveValidTrees 
    (P: List (rule τ)) (d: database τ) (l: List (proofTree τ)) 
    (ruleToString: rule τ → String) : validateTreeList P d l  ruleToString = Except.ok () ↔
    {ga: groundAtom τ| ∃ (t: proofTree τ), t ∈ l ∧ elementMember ga t } ⊆ proofTheoreticSemantics P.toFinset d 
    ∧ ∀ (t: proofTree τ), t ∈ l → isValid P.toFinset d t
\end{lstlisting}

Now it is enough to pass just one proof tree from our example to validate the whole input and use in general less trees. 
